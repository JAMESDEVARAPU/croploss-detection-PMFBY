import record from "node-record-lpcm16";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import { voiceService } from "./voice-service";

// Fix __dirname and __filename for ES modules
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Resolve wakeword.ppn path relative to the server directory
const absPath = path.resolve(__dirname, "..", "wakeword.ppn");

// Check if file exists
if (!fs.existsSync(absPath)) {
  console.warn(`âš ï¸ Wake word file not found at: ${absPath}`);
  console.warn(`Please ensure wakeword.ppn file is placed in the server directory`);
  console.warn(`You can download wakeword models from: https://picovoice.ai/custom-wake-word/`);
}

const RECORD_DURATION_MS = 5000;

export class WakeWordService {
  private isListening = false;
  private isActive = false;
  private wakeWordCallbacks: ((detected: boolean) => void)[] = [];
  private intervalId: NodeJS.Timeout | null = null;
  private selectedLanguage: 'en' | 'hi' | 'te' = 'en';
  private femaleVoice = true;

  async start() {
    if (this.isActive) {
      console.log("âš ï¸ Wake word service is already active");
      return;
    }

    try {
      // Check for required environment variables
      if (!process.env.PICOVOICE_KEY) {
        console.warn("âš ï¸ Missing PICOVOICE_KEY in environment variables");
        console.warn("Wake word service will be disabled. Set PICOVOICE_KEY in your .env file to enable.");
        console.warn("Get your key from: https://picovoice.ai/console/");
        return;
      }

      // Check if wakeword file exists
      if (!fs.existsSync(absPath)) {
        console.warn("âš ï¸ Wake word model file not found");
        console.warn(`Expected location: ${absPath}`);
        console.warn("Wake word service will be disabled. Download a wakeword model from: https://picovoice.ai/custom-wake-word/");
        return;
      }

      console.log("ðŸ” Using wakeword path:", absPath);
      console.log("âœ… Wake word service started. Say 'Hey KrishiRakshak' to activate.");

      const { Porcupine } = await import("@picovoice/porcupine-node");
      const { PvRecorder } = await import("@picovoice/pvrecorder-node");

      const porcupine = new Porcupine(
        process.env.PICOVOICE_KEY!,
        [absPath],
        [0.7] // Sensitivity level
      );

      // ðŸ” Auto-detect audio device
      const devices = PvRecorder.getAvailableDevices();
      console.log("ðŸŽ¤ Available audio devices:", devices);

      let deviceIndex = -1; // -1 means default system device
      if (devices.length > 0) {
        deviceIndex = 0; // pick the first available mic
        console.log(`âœ… Using device index ${deviceIndex}: ${devices[deviceIndex]}`);
      } else {
        console.warn("âš ï¸ No audio devices found. PvRecorder may fail to start.");
      }

      // â— FIX: constructor expects (frameLength, deviceIndex, bufferedFramesCount?)
      const recorder = new PvRecorder(porcupine.frameLength, deviceIndex);
      console.log(
        `â„¹ï¸ PvRecorder initialized â†’ frameLength=${porcupine.frameLength}, sampleRate=${PvRecorder.prototype.sampleRate ?? 16000}`
      );

      recorder.start();
      console.log("ðŸŽ¤ Microphone listening for wake word...");

      const processAudio = async () => {
        try {
          if (!this.isActive || this.isListening) return;

          const frame = (await (recorder as any).read()) as Int16Array;
          const keywordIndex = porcupine.process(frame);

          if (keywordIndex >= 0) {
            console.log("ðŸ”” Wake word detected!");
            this.isListening = true;

            this.wakeWordCallbacks.forEach((callback) => callback(true));

            try {
              await this.onWakeWord();
            } catch (error) {
              console.error("Error processing wake word:", error);
            } finally {
              this.isListening = false;
              this.wakeWordCallbacks.forEach((callback) => callback(false));
            }
          }
        } catch (err) {
          console.error("Error processing audio frame:", err);
        }
      };

      this.intervalId = setInterval(processAudio, 100);
      this.isActive = true;

      const shutdown = () => {
        console.log("ðŸ›‘ Shutting down wake word service...");
        if (this.intervalId) {
          clearInterval(this.intervalId);
        }
        try {
          recorder.stop();
        } catch {}
        try {
          porcupine.release();
        } catch {}
        this.isActive = false;
        process.exit(0);
      };

      process.on("SIGINT", shutdown);
      process.on("SIGTERM", shutdown);
    } catch (err) {
      console.error("âŒ Failed to start wake word service:", err);
      console.error("Make sure you have:");
      console.error("1. Set PICOVOICE_KEY environment variable");
      console.error("2. Downloaded wakeword.ppn file");
      console.error("3. Installed @picovoice/porcupine-node and @picovoice/pvrecorder-node");
      this.isActive = false;
    }
  }

  async stop() {
    console.log("ðŸ›‘ Stopping wake word service...");
    this.isActive = false;
    this.isListening = false;
    if (this.intervalId) {
      clearInterval(this.intervalId);
      this.intervalId = null;
    }
  }

  getStatus() {
    return {
      isActive: this.isActive,
      isListening: this.isListening,
      wakeWordModel: fs.existsSync(absPath) ? "loaded" : "missing",
    };
  }

  onWakeWordDetected(callback: (detected: boolean) => void) {
    this.wakeWordCallbacks.push(callback);
  }

  removeWakeWordCallback(callback: (detected: boolean) => void) {
    const index = this.wakeWordCallbacks.indexOf(callback);
    if (index > -1) {
      this.wakeWordCallbacks.splice(index, 1);
    }
  }

  setLanguage(language: 'en' | 'hi' | 'te') {
    this.selectedLanguage = language;
    console.log(`ðŸŒ Language set to: ${language}`);
  }

  setVoiceGender(female: boolean) {
    this.femaleVoice = female;
    console.log(`ðŸŽ¤ Voice gender set to: ${female ? 'Female' : 'Male'}`);
  }

  private async onWakeWord() {
    console.log("ðŸ”” Wake word 'Hey KrishiRakshak' detected!");
    console.log("ðŸŽ¤ Listening for your command...");

    try {
      // Multilingual greeting
      const greetings = {
        en: "Hello! How can I help you with your crops today?",
        hi: "à¤¨à¤®à¤¸à¥à¤¤à¥‡! à¤†à¤œ à¤®à¥ˆà¤‚ à¤†à¤ªà¤•à¥€ à¤«à¤¸à¤² à¤•à¥‡ à¤¸à¤¾à¤¥ à¤•à¥ˆà¤¸à¥‡ à¤®à¤¦à¤¦ à¤•à¤° à¤¸à¤•à¤¤à¥€ à¤¹à¥‚à¤‚?",
        te: "à°¨à°®à°¸à±à°•à°¾à°°à°‚! à°ˆà°°à±‹à°œà± à°®à±€ à°ªà°‚à°Ÿà°²à°¤à±‹ à°¨à±‡à°¨à± à°Žà°²à°¾ à°¸à°¹à°¾à°¯à°‚ à°šà±‡à°¯à°—à°²à°¨à±?"
      };
      
      const listeningMessage = greetings[this.selectedLanguage];
      console.log("ðŸŽµ Playing:", listeningMessage);
      await this.speakResponse(listeningMessage);

      const audioBuffer = await this.recordUserAudio(RECORD_DURATION_MS);

      if (!audioBuffer || audioBuffer.length === 0) {
        console.log("âŒ No audio recorded");
        const errorMessages = {
          en: "Sorry, I didn't hear anything. Please try again.",
          hi: "à¤®à¤¾à¤« à¤•à¤°à¥‡à¤‚, à¤®à¥à¤à¥‡ à¤•à¥à¤› à¤¸à¥à¤¨à¤¾à¤ˆ à¤¨à¤¹à¥€à¤‚ à¤¦à¤¿à¤¯à¤¾à¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤«à¤¿à¤° à¤¸à¥‡ à¤•à¥‹à¤¶à¤¿à¤¶ à¤•à¤°à¥‡à¤‚à¥¤",
          te: "à°•à±à°·à°®à°¿à°‚à°šà°‚à°¡à°¿, à°¨à°¾à°•à± à°à°®à±€ à°µà°¿à°¨à°¿à°ªà°¿à°‚à°šà°²à±‡à°¦à±. à°¦à°¯à°šà±‡à°¸à°¿ à°®à°³à±à°²à±€ à°ªà±à°°à°¯à°¤à±à°¨à°¿à°‚à°šà°‚à°¡à°¿."
        };
        await this.speakResponse(errorMessages[this.selectedLanguage]);
        return;
      }

      console.log("ðŸ“ Processing speech...");
      const transcription = await voiceService.speechToText(audioBuffer);

      if (!transcription.success || !transcription.transcription) {
        console.log("âŒ Speech recognition failed:", transcription.error);
        const errorMessages = {
          en: "Sorry, I couldn't understand that. Please try again.",
          hi: "à¤®à¤¾à¤« à¤•à¤°à¥‡à¤‚, à¤®à¥ˆà¤‚ à¤¸à¤®à¤ à¤¨à¤¹à¥€à¤‚ à¤ªà¤¾à¤ˆà¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤«à¤¿à¤° à¤¸à¥‡ à¤•à¥‹à¤¶à¤¿à¤¶ à¤•à¤°à¥‡à¤‚à¥¤",
          te: "à°•à±à°·à°®à°¿à°‚à°šà°‚à°¡à°¿, à°¨à°¾à°•à± à°…à°°à±à°¥à°‚ à°•à°¾à°²à±‡à°¦à±. à°¦à°¯à°šà±‡à°¸à°¿ à°®à°³à±à°²à±€ à°ªà±à°°à°¯à°¤à±à°¨à°¿à°‚à°šà°‚à°¡à°¿."
        };
        await this.speakResponse(errorMessages[this.selectedLanguage]);
        return;
      }

      console.log("ðŸ—£ï¸ User said:", transcription.transcription);

      const command = voiceService.parseVoiceCommand(transcription.transcription);
      console.log("ðŸ” Parsed command:", command);

      const responseData = await this.executeCommand(command);

      const responseText = await voiceService.generateVoiceResponse(
        command.action,
        responseData,
        this.selectedLanguage
      );

      console.log("ðŸ’¬ Response:", responseText);
      await this.speakResponse(responseText);
    } catch (error) {
      console.error("âŒ Error in wake word processing:", error);
      const errorMessages = {
        en: "Sorry, there was an error processing your request.",
        hi: "à¤®à¤¾à¤« à¤•à¤°à¥‡à¤‚, à¤†à¤ªà¤•à¥‡ à¤…à¤¨à¥à¤°à¥‹à¤§ à¤•à¥‹ à¤¸à¤‚à¤¸à¤¾à¤§à¤¿à¤¤ à¤•à¤°à¤¨à¥‡ à¤®à¥‡à¤‚ à¤¤à¥à¤°à¥à¤Ÿà¤¿ à¤¹à¥à¤ˆà¥¤",
        te: "à°•à±à°·à°®à°¿à°‚à°šà°‚à°¡à°¿, à°®à±€ à°…à°­à±à°¯à°°à±à°¥à°¨à°¨à± à°ªà±à°°à°¾à°¸à±†à°¸à± à°šà±‡à°¯à°¡à°‚à°²à±‹ à°²à±‹à°ªà°‚ à°‰à°‚à°¦à°¿."
      };
      await this.speakResponse(errorMessages[this.selectedLanguage]);
    }
  }

  private async speakResponse(text: string) {
    try {
      const audioResponse = await voiceService.textToSpeech(text);
      if (audioResponse.success && audioResponse.audioUrl) {
        console.log("ðŸ”Š Female voice audio response generated:", audioResponse.audioUrl);
        // Play the audio
        if (typeof window !== 'undefined') {
          const audio = new Audio(audioResponse.audioUrl);
          audio.play().catch(console.error);
        }
      } else {
        console.log("âš ï¸ TTS failed, but response text:", text);
      }
    } catch (error) {
      console.error("âŒ Error generating speech response:", error);
    }
  }

  private async executeCommand(command: any) {
    switch (command.action) {
      case "crop_health":
        return await this.performNDVICheck(command);
      case "pmfby_eligibility":
        return await this.checkPMFBYEligibility(command);
      case "weather_forecast":
        return await this.getWeatherForecast(command);
      case "analyze":
        return await this.performAnalysis(command);
      default:
        return { action: "unknown", message: "Command not recognized" };
    }
  }

  private async performNDVICheck(command: any) {
    try {
      const { offlineModelService } = await import("./offline-model");
      const result = await offlineModelService.predictWithExplanation({
        ndviBefore: 0.7,
        ndviCurrent: 0.5,
        latitude: command.coordinates?.latitude || 20.5937,
        longitude: command.coordinates?.longitude || 78.9629,
        cropType: command.cropType || "rice",
      });

      return {
        cropType: command.cropType,
        lossPercentage: result.predictedLoss || 0,
        explanation: result.readableExplanation || "Analysis completed",
        ndviChange: this.calculateNDVIChange(result.featureExplanations),
      };
    } catch (error) {
      console.error('NDVI check error:', error);
      return {
        cropType: command.cropType || 'rice',
        lossPercentage: 0,
        explanation: 'Analysis failed',
        ndviChange: 0
      };
    }
  }

  private async checkPMFBYEligibility(command: any) {
    const isEligible = Math.random() > 0.5;
    return {
      eligible: isEligible,
      amount: isEligible ? Math.floor(Math.random() * 50000) + 10000 : 0,
      reason: isEligible ? 'Loss exceeds 33% threshold' : 'Loss below minimum threshold'
    };
  }

  private async getWeatherForecast(command: any) {
    return {
      temperature: Math.floor(Math.random() * 15) + 25,
      condition: 'Partly cloudy',
      recommendation: 'Good conditions for crop growth'
    };
  }

  private async performAnalysis(command: any) {
    return {
      coordinates: command.coordinates,
      cropType: command.cropType,
      status: 'Analysis completed'
    };
  }

  private calculateNDVIChange(featureExplanations?: any[]): number {
    if (!featureExplanations) return 0;
    const ndviBefore = featureExplanations.find(f => f.feature === 'ndvi_before')?.value || 0.7;
    const ndviCurrent = featureExplanations.find(f => f.feature === 'ndvi_current')?.value || 0.5;
    return Math.round(((ndviBefore - ndviCurrent) / ndviBefore) * 100);
  }

  private async recordUserAudio(duration: number): Promise<Buffer | null> {
    console.log(`ðŸŽ¤ Recording audio for ${duration}ms...`);
    await new Promise(resolve => setTimeout(resolve, duration));
    return Buffer.from('dummy-audio-data');
  }
}

export const wakeWordService = new WakeWordService();